{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f99f1b-f7a5-4354-b6f7-506901a9aa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilmar\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSVs and Excel: C:\\Users\\ilmar\\simple_monitor_output\n",
      "SMTP not configured via env vars. Skipping email.\n",
      "Done. Export folder: C:\\Users\\ilmar\\simple_monitor_output\n"
     ]
    }
   ],
   "source": [
    "# simple_campaign_monitor_with_export.py\n",
    "# Minimal campaign daily monitor + CSV + Excel export + email alerts\n",
    "# Email subject = \"Campaign report alerts - <date>\" where <date> = (latest_date_in_data - 1 day)\n",
    "# Requirements: pandas, openpyxl (for Excel export)\n",
    "# Optional for email: set SMTP env vars (ALERT_SMTP_*)\n",
    "\n",
    "import os\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# -------------------- CONFIG (edit these) --------------------\n",
    "INPUT_PATH =\"D:\\Downloads\\query_result_2025-10-16T05_46_10.207636705Z.xlsx\" # Excel or CSV\n",
    "HIST_DAYS = 30                # how many days to use for \"historical\" average\n",
    "MIN_IMPRESSIONS = 100         # ignore tiny rows\n",
    "MIN_CLICKS = 5\n",
    "# thresholds: fraction relative to historical average. Positive=alert on increase, Negative=alert on drop.\n",
    "THRESHOLDS = {\n",
    "    \"ctr\": 0.50,              # CTR >= hist*(1+0.5)\n",
    "    \"cpc\": 0.50,              # CPC >= hist*(1+0.5)\n",
    "    \"conversion_rate\": -0.30, # CVR <= hist*(1-0.3) (drop)\n",
    "    \"cpa\": 0.50               # CPA increase\n",
    "}\n",
    "# Column names in your file. Change here if your file uses different names.\n",
    "DATE_COL = \"date\"\n",
    "CAMPAIGN_ID = \"campaign_id\"\n",
    "CAMPAIGN_NAME = \"campaign_name\"\n",
    "ACCOUNT_COL = \"account_id\"   # optional; will be created as \"unknown_account\" if missing\n",
    "BRAND_COL = \"brand\"          # optional; will be created as \"unknown_brand\" if missing\n",
    "OUTPUT_DIR = \"simple_monitor_output\"\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "EPS = 1e-9\n",
    "\n",
    "def safe_div(a, b):\n",
    "    return np.where(b == 0, 0.0, a / b)\n",
    "\n",
    "def load_data(path):\n",
    "    if str(path).lower().endswith((\".xls\", \".xlsx\")):\n",
    "        return pd.read_excel(path, engine=\"openpyxl\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def ensure_columns(df):\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    # find date column if needed\n",
    "    if DATE_COL not in df.columns:\n",
    "        candidates = [c for c in df.columns if \"date\" in c.lower()]\n",
    "        if candidates:\n",
    "            df.rename(columns={candidates[0]: DATE_COL}, inplace=True)\n",
    "    df[DATE_COL] = pd.to_datetime(df[DATE_COL]).dt.normalize()\n",
    "\n",
    "    # numeric columns\n",
    "    for c in [\"impressions\", \"clicks\", \"cost\", \"conversions\", \"conversion_value\"]:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # campaign id/name mapping or generate\n",
    "    if CAMPAIGN_ID not in df.columns:\n",
    "        alt = [c for c in df.columns if \"campaign\" in c.lower() and \"id\" in c.lower()]\n",
    "        if alt:\n",
    "            df.rename(columns={alt[0]: CAMPAIGN_ID}, inplace=True)\n",
    "        else:\n",
    "            df[CAMPAIGN_ID] = df.index.astype(str)\n",
    "    if CAMPAIGN_NAME not in df.columns:\n",
    "        alt = [c for c in df.columns if \"campaign\" in c.lower() and \"name\" in c.lower()]\n",
    "        if alt:\n",
    "            df.rename(columns={alt[0]: CAMPAIGN_NAME}, inplace=True)\n",
    "        else:\n",
    "            df[CAMPAIGN_NAME] = df[CAMPAIGN_ID].astype(str)\n",
    "\n",
    "    # optional account/brand\n",
    "    if ACCOUNT_COL not in df.columns:\n",
    "        df[ACCOUNT_COL] = \"unknown_account\"\n",
    "    if BRAND_COL not in df.columns:\n",
    "        df[BRAND_COL] = \"unknown_brand\"\n",
    "\n",
    "    return df\n",
    "\n",
    "def compute_daily(df):\n",
    "    group = [DATE_COL, ACCOUNT_COL, BRAND_COL, CAMPAIGN_ID, CAMPAIGN_NAME]\n",
    "    agg = df.groupby(group, as_index=False).agg({\n",
    "        \"impressions\":\"sum\", \"clicks\":\"sum\", \"cost\":\"sum\",\n",
    "        \"conversions\":\"sum\", \"conversion_value\":\"sum\"\n",
    "    })\n",
    "    agg[\"ctr\"] = safe_div(agg[\"clicks\"], agg[\"impressions\"])\n",
    "    agg[\"cpc\"] = safe_div(agg[\"cost\"], agg[\"clicks\"])\n",
    "    agg[\"conversion_rate\"] = safe_div(agg[\"conversions\"], agg[\"clicks\"])\n",
    "    agg[\"cpa\"] = safe_div(agg[\"cost\"], agg[\"conversions\"])\n",
    "    agg[\"roi\"] = safe_div(agg[\"conversion_value\"], agg[\"cost\"])\n",
    "    return agg\n",
    "\n",
    "def historical_average(metrics_df, target_date, days):\n",
    "    hist_end = pd.to_datetime(target_date) - pd.Timedelta(days=1)\n",
    "    hist_start = hist_end - pd.Timedelta(days=days-1)\n",
    "    hist = metrics_df[(metrics_df[DATE_COL] >= hist_start) & (metrics_df[DATE_COL] <= hist_end)]\n",
    "    if hist.empty:\n",
    "        return pd.DataFrame()  # nothing\n",
    "    cols = [ACCOUNT_COL, BRAND_COL, CAMPAIGN_ID]\n",
    "    hist_avg = hist.groupby(cols).agg({\n",
    "        \"impressions\":\"mean\",\"clicks\":\"mean\",\"cost\":\"mean\",\n",
    "        \"conversions\":\"mean\",\"conversion_value\":\"mean\",\n",
    "        \"ctr\":\"mean\",\"cpc\":\"mean\",\"conversion_rate\":\"mean\",\"cpa\":\"mean\",\"roi\":\"mean\"\n",
    "    }).reset_index()\n",
    "    # rename historical cols with _hist suffix for clarity\n",
    "    hist_avg = hist_avg.rename(columns={c: f\"{c}_hist\" for c in hist_avg.columns if c not in cols})\n",
    "    return hist_avg\n",
    "\n",
    "def detect_breaches(target_day_df, hist_avg_df):\n",
    "    merged = target_day_df.merge(hist_avg_df, on=[ACCOUNT_COL, BRAND_COL, CAMPAIGN_ID], how=\"left\")\n",
    "    # percent changes relative to historical avg\n",
    "    merged[\"ctr_pct\"] = (merged[\"ctr\"] - merged.get(\"ctr_hist\", 0)) / (merged.get(\"ctr_hist\", 0) + EPS)\n",
    "    merged[\"cpc_pct\"] = (merged[\"cpc\"] - merged.get(\"cpc_hist\", 0)) / (merged.get(\"cpc_hist\", 0) + EPS)\n",
    "    merged[\"conv_rate_pct\"] = (merged[\"conversion_rate\"] - merged.get(\"conversion_rate_hist\", 0)) / (merged.get(\"conversion_rate_hist\", 0) + EPS)\n",
    "    merged[\"cpa_pct\"] = (merged[\"cpa\"] - merged.get(\"cpa_hist\", 0)) / (merged.get(\"cpa_hist\", 0) + EPS)\n",
    "\n",
    "    alerts = []\n",
    "    for _, r in merged.iterrows():\n",
    "        if r[\"impressions\"] < MIN_IMPRESSIONS or r[\"clicks\"] < MIN_CLICKS:\n",
    "            continue\n",
    "        breach_items = []\n",
    "        if \"ctr\" in THRESHOLDS and pd.notnull(r.get(\"ctr_hist\")):\n",
    "            if r[\"ctr_pct\"] >= THRESHOLDS[\"ctr\"]:\n",
    "                breach_items.append((\"ctr\", r[\"ctr\"], r.get(\"ctr_hist\"), r[\"ctr_pct\"]))\n",
    "        if \"cpc\" in THRESHOLDS and pd.notnull(r.get(\"cpc_hist\")):\n",
    "            if r[\"cpc_pct\"] >= THRESHOLDS[\"cpc\"]:\n",
    "                breach_items.append((\"cpc\", r[\"cpc\"], r.get(\"cpc_hist\"), r[\"cpc_pct\"]))\n",
    "        if \"conversion_rate\" in THRESHOLDS and pd.notnull(r.get(\"conversion_rate_hist\")):\n",
    "            th = THRESHOLDS[\"conversion_rate\"]\n",
    "            if th < 0 and r[\"conv_rate_pct\"] <= th:\n",
    "                breach_items.append((\"conversion_rate_drop\", r[\"conversion_rate\"], r.get(\"conversion_rate_hist\"), r[\"conv_rate_pct\"]))\n",
    "            elif th >= 0 and r[\"conv_rate_pct\"] >= th:\n",
    "                breach_items.append((\"conversion_rate_rise\", r[\"conversion_rate\"], r.get(\"conversion_rate_hist\"), r[\"conv_rate_pct\"]))\n",
    "        if \"cpa\" in THRESHOLDS and pd.notnull(r.get(\"cpa_hist\")):\n",
    "            if r[\"cpa_pct\"] >= THRESHOLDS[\"cpa\"]:\n",
    "                breach_items.append((\"cpa\", r[\"cpa\"], r.get(\"cpa_hist\"), r[\"cpa_pct\"]))\n",
    "        if breach_items:\n",
    "            alerts.append({\n",
    "                \"account\": r[ACCOUNT_COL],\n",
    "                \"brand\": r[BRAND_COL],\n",
    "                \"campaign_id\": r[CAMPAIGN_ID],\n",
    "                \"campaign_name\": r[CAMPAIGN_NAME],\n",
    "                \"date\": r[DATE_COL].date().isoformat(),\n",
    "                \"impressions\": int(r[\"impressions\"]),\n",
    "                \"clicks\": int(r[\"clicks\"]),\n",
    "                \"cost\": float(r[\"cost\"]),\n",
    "                \"conversions\": int(r[\"conversions\"]),\n",
    "                \"conversion_value\": float(r[\"conversion_value\"]),\n",
    "                \"breach_details\": \"; \".join([f\"{m}: {cur:.4g} vs {hist:.4g} ({pct:+.1%})\" for m,cur,hist,pct in breach_items])\n",
    "            })\n",
    "    return pd.DataFrame(alerts), merged\n",
    "\n",
    "def send_email(subject, html_body):\n",
    "    host = os.getenv(\"ALERT_SMTP_HOST\")\n",
    "    port = int(os.getenv(\"ALERT_SMTP_PORT\", \"587\"))\n",
    "    user = os.getenv(\"ALERT_SMTP_USER\")\n",
    "    pwd = os.getenv(\"ALERT_SMTP_PASS\")\n",
    "    from_addr = os.getenv(\"ALERT_FROM\")\n",
    "    to_addrs = os.getenv(\"ALERT_TO\")\n",
    "    if not all([host, user, pwd, from_addr, to_addrs]):\n",
    "        print(\"SMTP not configured via env vars. Skipping email.\")\n",
    "        return False\n",
    "    to_list = [t.strip() for t in to_addrs.split(\",\") if t.strip()]\n",
    "    msg = MIMEText(html_body, \"html\")\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = from_addr\n",
    "    msg[\"To\"] = \", \".join(to_list)\n",
    "    try:\n",
    "        s = smtplib.SMTP(host, port, timeout=20)\n",
    "        s.starttls()\n",
    "        s.login(user, pwd)\n",
    "        s.sendmail(from_addr, to_list, msg.as_string())\n",
    "        s.quit()\n",
    "        print(\"Email sent to:\", to_list)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Failed to send email:\", e)\n",
    "        return False\n",
    "\n",
    "def export_reports(daily_all, daily_target, alerts_df, target_date):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    date_str = target_date.strftime(\"%Y%m%d\")\n",
    "    # CSVs\n",
    "    daily_all.to_csv(os.path.join(OUTPUT_DIR, f\"daily_all_{date_str}.csv\"), index=False)\n",
    "    daily_target.to_csv(os.path.join(OUTPUT_DIR, f\"daily_target_{date_str}.csv\"), index=False)\n",
    "    alerts_df.to_csv(os.path.join(OUTPUT_DIR, f\"alerts_{date_str}.csv\"), index=False)\n",
    "    # Single Excel workbook with sheets\n",
    "    try:\n",
    "        excel_path = os.path.join(OUTPUT_DIR, f\"campaign_report_{date_str}.xlsx\")\n",
    "        with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "            daily_all.to_excel(writer, sheet_name=\"daily_all\", index=False)\n",
    "            daily_target.to_excel(writer, sheet_name=\"daily_target\", index=False)\n",
    "            alerts_df.to_excel(writer, sheet_name=\"alerts\", index=False)\n",
    "        print(\"Saved CSVs and Excel:\", os.path.abspath(OUTPUT_DIR))\n",
    "    except Exception as e:\n",
    "        print(\"Excel export skipped (openpyxl missing or error):\", e)\n",
    "\n",
    "def run_monitor():\n",
    "    df_raw = load_data(INPUT_PATH)\n",
    "    df = ensure_columns(df_raw)\n",
    "    daily = compute_daily(df)\n",
    "\n",
    "    if daily.empty:\n",
    "        print(\"No data found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    latest_date = daily[DATE_COL].max()\n",
    "    target_date = latest_date  # using latest date as the date we check\n",
    "    previous_day_for_subject = (latest_date - pd.Timedelta(days=1)).date().isoformat()\n",
    "\n",
    "    # prepare target day data\n",
    "    target_day = daily[daily[DATE_COL] == target_date].copy()\n",
    "    if target_day.empty:\n",
    "        print(\"No rows for latest date:\", latest_date.date(), \"Exiting.\")\n",
    "        return\n",
    "\n",
    "    hist_avg = historical_average(daily, target_date, HIST_DAYS)\n",
    "    alerts_df, merged_full = detect_breaches(target_day, hist_avg)\n",
    "\n",
    "    # export CSV + Excel\n",
    "    export_reports(daily, target_day, alerts_df, target_date)\n",
    "\n",
    "    # compose email\n",
    "    subject = f\"Campaign report alerts - {previous_day_for_subject}\"\n",
    "    if alerts_df.empty:\n",
    "        body_html = f\"<p>Hi Team,</p><p>No campaign breaches detected for <b>{target_date.date()}</b>.</p>\"\n",
    "    else:\n",
    "        body_html = f\"<p>Hi Team,</p><p>Campaign breaches detected for <b>{target_date.date()}</b> (historical window: last {HIST_DAYS} days).</p>\"\n",
    "        body_html += alerts_df.to_html(index=False, escape=False)\n",
    "        body_html += \"<p>CSV and Excel reports saved in folder: {}</p>\".format(os.path.abspath(OUTPUT_DIR))\n",
    "\n",
    "    send_email(subject, body_html)\n",
    "    print(\"Done. Export folder:\", os.path.abspath(OUTPUT_DIR))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_monitor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc618356-4f74-4855-a228-501624796103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Collecting google-ads\n",
      "  Downloading google_ads-28.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Collecting google-auth-oauthlib<2.0.0,>=1.0.0 (from google-ads)\n",
      "  Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-core<=3.0.0,>=2.13.0 (from google-ads)\n",
      "  Downloading google_api_core-2.26.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.3 (from google-ads)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting grpcio<2.0.0,>=1.59.0 (from google-ads)\n",
      "  Downloading grpcio-1.75.1-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.59.0 (from google-ads)\n",
      "  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ads)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: PyYAML<7.0,>=5.1 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from google-ads) (6.0.1)\n",
      "Collecting protobuf<7.0.0,>=4.25.0 (from google-ads)\n",
      "  Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: et_xmlfile in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-api-core<=3.0.0,>=2.13.0->google-ads)\n",
      "  Downloading google_auth-2.41.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from google-api-core<=3.0.0,>=2.13.0->google-ads) (2.31.0)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2.0.0,>=1.0.0->google-ads)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting typing-extensions~=4.12 (from grpcio<2.0.0,>=1.59.0->google-ads)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<=3.0.0,>=2.13.0->google-ads) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<=3.0.0,>=2.13.0->google-ads) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-api-core<=3.0.0,>=2.13.0->google-ads)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core<=3.0.0,>=2.13.0->google-ads) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core<=3.0.0,>=2.13.0->google-ads) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core<=3.0.0,>=2.13.0->google-ads) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core<=3.0.0,>=2.13.0->google-ads) (2024.2.2)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2.0.0,>=1.0.0->google-ads)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ilmar\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<=3.0.0,>=2.13.0->google-ads) (0.4.8)\n",
      "Downloading google_ads-28.1.0-py3-none-any.whl (17.8 MB)\n",
      "   ---------------------------------------- 0.0/17.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/17.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/17.8 MB 5.3 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.2/17.8 MB 5.3 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.5/17.8 MB 2.4 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.3/17.8 MB 5.3 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.7/17.8 MB 5.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.2/17.8 MB 6.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.4/17.8 MB 5.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.4/17.8 MB 5.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.4/17.8 MB 5.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.4/17.8 MB 5.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.4/17.8 MB 5.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.4/17.8 MB 5.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.4/17.8 MB 5.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.4/17.8 MB 3.3 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.6/17.8 MB 3.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.8/17.8 MB 3.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.9/17.8 MB 3.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.0/17.8 MB 3.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.1/17.8 MB 3.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 3.1/17.8 MB 3.1 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 3.2/17.8 MB 3.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 3.2/17.8 MB 2.9 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 3.3/17.8 MB 2.8 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 3.3/17.8 MB 2.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 3.3/17.8 MB 2.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 3.4/17.8 MB 2.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.6/17.8 MB 2.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.7/17.8 MB 2.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.8/17.8 MB 2.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 4.0/17.8 MB 2.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 4.2/17.8 MB 2.7 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 4.4/17.8 MB 2.7 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 4.6/17.8 MB 2.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 4.9/17.8 MB 2.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 5.2/17.8 MB 2.9 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 5.4/17.8 MB 3.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 5.6/17.8 MB 3.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 5.7/17.8 MB 3.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 6.0/17.8 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 6.1/17.8 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 6.2/17.8 MB 3.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 6.3/17.8 MB 3.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 6.3/17.8 MB 3.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 6.5/17.8 MB 2.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 6.5/17.8 MB 2.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 6.6/17.8 MB 2.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 6.6/17.8 MB 2.9 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 6.7/17.8 MB 2.8 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 6.9/17.8 MB 2.9 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 7.3/17.8 MB 2.9 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 7.5/17.8 MB 3.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 7.9/17.8 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 8.3/17.8 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 8.7/17.8 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 9.1/17.8 MB 3.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 9.4/17.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 10.0/17.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 10.2/17.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 10.7/17.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 11.2/17.8 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 11.7/17.8 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 12.0/17.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 12.8/17.8 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 13.1/17.8 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 13.6/17.8 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 14.2/17.8 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 14.7/17.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 15.2/17.8 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 15.6/17.8 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 16.1/17.8 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 16.6/17.8 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.1/17.8 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/17.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/17.8 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 17.8/17.8 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.26.0-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.5/162.5 kB 9.5 MB/s eta 0:00:00\n",
      "Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 294.5/294.5 kB 19.0 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.75.1-cp311-cp311-win_amd64.whl (4.6 MB)\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.6/4.6 MB 12.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.9/4.6 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.2/4.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.6/4.6 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.0/4.6 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.6/4.6 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.8/4.6 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.1/4.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.4/4.6 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.6/4.6 MB 7.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.9/4.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.3/4.6 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.6/4.6 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.6/4.6 MB 7.2 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.75.1-py3-none-any.whl (14 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB ? eta 0:00:00\n",
      "Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "   ---------------------------------------- 0.0/436.9 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 112.6/436.9 kB 3.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 204.8/436.9 kB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 286.7/436.9 kB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 368.6/436.9 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 436.9/436.9 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "   ---------------------------------------- 0.0/221.3 kB ? eta -:--:--\n",
      "   ------- ------------------------------- 41.0/221.3 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------- ---------------------- 92.2/221.3 kB 871.5 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 153.6/221.3 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 221.3/221.3 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.6/44.6 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.1 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 92.2/160.1 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 153.6/160.1 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 160.1/160.1 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: typing-extensions, rsa, protobuf, oauthlib, requests-oauthlib, proto-plus, grpcio, googleapis-common-protos, google-auth, grpcio-status, google-auth-oauthlib, google-api-core, google-ads\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "Successfully installed google-ads-28.1.0 google-api-core-2.26.0 google-auth-2.41.1 google-auth-oauthlib-1.2.2 googleapis-common-protos-1.70.0 grpcio-1.75.1 grpcio-status-1.75.1 oauthlib-3.3.1 proto-plus-1.26.1 protobuf-6.33.0 requests-oauthlib-2.0.0 rsa-4.9.1 typing-extensions-4.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.30.0 requires protobuf<5,>=3.20, but you have protobuf 6.33.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas google-ads openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78e296-7d6c-47e0-8c39-572c3aab3e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# campaign_monitor_google_ads.py\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Try to import google-ads client; fail gracefully with instructions\n",
    "try:\n",
    "    from google.ads.googleads.client import GoogleAdsClient\n",
    "except Exception as e:\n",
    "    GoogleAdsClient = None\n",
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "# Google Ads: list of customer IDs (strings, e.g. \"1234567890\")\n",
    "CUSTOMER_IDS = [\"INSERT_CUSTOMER_ID_HERE\"]\n",
    "\n",
    "# Date window to fetch (we'll fetch last N days up to yesterday)\n",
    "LOOKBACK_DAYS = 90\n",
    "\n",
    "# Monitor settings\n",
    "HIST_DAYS = 30\n",
    "MIN_IMPRESSIONS = 100\n",
    "MIN_CLICKS = 5\n",
    "THRESHOLDS = {\n",
    "    \"ctr\": 0.50,                # CTR increased >= 50% vs hist\n",
    "    \"cpc\": 0.50,                # CPC increased >= 50%\n",
    "    \"conversion_rate\": -0.30,   # CVR decreased >= 30% (negative means drop)\n",
    "    \"cpa\": 0.50                 # CPA increased >= 50%\n",
    "}\n",
    "\n",
    "# Output\n",
    "OUTPUT_DIR = \"ga_campaign_monitor_output\"\n",
    "\n",
    "# Default email addresses (user requested)\n",
    "DEFAULT_EMAIL = \"ilmazeem3@gmail.com\"\n",
    "EMAIL_FROM = os.getenv(\"EMAIL_FROM\", DEFAULT_EMAIL)\n",
    "EMAIL_TO = os.getenv(\"EMAIL_TO\", DEFAULT_EMAIL)  # comma-separated allowed\n",
    "\n",
    "EPS = 1e-9\n",
    "\n",
    "def send_email(subject, html_body):\n",
    "    host = os.getenv(\"EMAIL_SMTP_HOST\")\n",
    "    port = int(os.getenv(\"EMAIL_SMTP_PORT\", \"587\"))\n",
    "    user = os.getenv(\"EMAIL_SMTP_USER\")\n",
    "    pwd = os.getenv(\"EMAIL_SMTP_PASS\")\n",
    "    from_addr = EMAIL_FROM\n",
    "    to_addrs = EMAIL_TO\n",
    "\n",
    "    if not all([host, user, pwd, from_addr, to_addrs]):\n",
    "        print(\"SMTP not fully configured via env vars. Email will be skipped. (Set EMAIL_SMTP_* vars)\")\n",
    "        return False\n",
    "\n",
    "    to_list = [x.strip() for x in to_addrs.split(\",\") if x.strip()]\n",
    "    msg = MIMEText(html_body, \"html\")\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = from_addr\n",
    "    msg[\"To\"] = \", \".join(to_list)\n",
    "\n",
    "    try:\n",
    "        server = smtplib.SMTP(host, port, timeout=20)\n",
    "        server.starttls()\n",
    "        server.login(user, pwd)\n",
    "        server.sendmail(from_addr, to_list, msg.as_string())\n",
    "        server.quit()\n",
    "        print(\"Email sent to:\", to_list)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Failed to send email:\", e)\n",
    "        return False\n",
    "\n",
    "# ---------- Google Ads extraction ----------\n",
    "def get_google_ads_client():\n",
    "    if GoogleAdsClient is None:\n",
    "        raise ImportError(\"google-ads library not installed. Run: pip install google-ads\")\n",
    "    # First try loading from default yaml\n",
    "    try:\n",
    "        client = GoogleAdsClient.load_from_storage()\n",
    "        return client\n",
    "    except Exception:\n",
    "        # Optionally try to build client from environment vars (simple)\n",
    "        cfg = {}\n",
    "        # required env vars: GOOGLE_ADS_DEVELOPER_TOKEN, GOOGLE_ADS_CLIENT_ID, GOOGLE_ADS_CLIENT_SECRET, GOOGLE_ADS_REFRESH_TOKEN\n",
    "        token = os.getenv(\"GOOGLE_ADS_DEVELOPER_TOKEN\")\n",
    "        cid = os.getenv(\"GOOGLE_ADS_CLIENT_ID\")\n",
    "        secret = os.getenv(\"GOOGLE_ADS_CLIENT_SECRET\")\n",
    "        refresh = os.getenv(\"GOOGLE_ADS_REFRESH_TOKEN\")\n",
    "        login_cust = os.getenv(\"GOOGLE_ADS_LOGIN_CUSTOMER_ID\")  # optional\n",
    "        if not all([token, cid, secret, refresh]):\n",
    "            raise RuntimeError(\"Google Ads credentials not found. Use google-ads.yaml or set env vars: GOOGLE_ADS_DEVELOPER_TOKEN, GOOGLE_ADS_CLIENT_ID, GOOGLE_ADS_CLIENT_SECRET, GOOGLE_ADS_REFRESH_TOKEN\")\n",
    "        cfg[\"developer_token\"] = token\n",
    "        cfg[\"client_id\"] = cid\n",
    "        cfg[\"client_secret\"] = secret\n",
    "        cfg[\"refresh_token\"] = refresh\n",
    "        if login_cust:\n",
    "            cfg[\"login_customer_id\"] = login_cust\n",
    "        # build minimal config dict structure expected by client library\n",
    "        client = GoogleAdsClient.load_from_dict({\"developer_token\": token,\n",
    "                                                 \"client_id\": cid,\n",
    "                                                 \"client_secret\": secret,\n",
    "                                                 \"refresh_token\": refresh,\n",
    "                                                 \"login_customer_id\": login_cust} )\n",
    "        return client\n",
    "\n",
    "def fetch_google_ads_data(customer_ids, lookback_days=LOOKBACK_DAYS):\n",
    "    client = get_google_ads_client()\n",
    "    ga_service = client.get_service(\"GoogleAdsService\")\n",
    "    rows = []\n",
    "    end_date = (datetime.utcnow().date() - timedelta(days=1))  # up to yesterday\n",
    "    start_date = end_date - timedelta(days=lookback_days - 1)\n",
    "    # GAQL: campaign resource supports campaign fields + metrics + segments.date\n",
    "    gaql = f\"\"\"\n",
    "      SELECT\n",
    "        customer.id,\n",
    "        campaign.id,\n",
    "        campaign.name,\n",
    "        segments.date,\n",
    "        metrics.impressions,\n",
    "        metrics.clicks,\n",
    "        metrics.cost_micros,\n",
    "        metrics.conversions,\n",
    "        metrics.conversions_value\n",
    "      FROM campaign\n",
    "      WHERE segments.date BETWEEN '{start_date.isoformat()}' AND '{end_date.isoformat()}'\n",
    "      ORDER BY segments.date\n",
    "    \"\"\"\n",
    "    for cust in customer_ids:\n",
    "        # google-ads client expects a string customer_id with no dashes\n",
    "        cust_str = cust.replace(\"-\", \"\").strip()\n",
    "        response = ga_service.search(customer_id=cust_str, query=gaql, page_size=10000)\n",
    "        for result in response:\n",
    "            # result is a GoogleAdsRow protobuf object; access fields carefully\n",
    "            cust_id = getattr(result.customer, \"id\", None)\n",
    "            campaign = getattr(result, \"campaign\", None)\n",
    "            seg_date = getattr(result.segments, \"date\", None)\n",
    "            impressions = getattr(result.metrics, \"impressions\", 0)\n",
    "            clicks = getattr(result.metrics, \"clicks\", 0)\n",
    "            cost_micros = getattr(result.metrics, \"cost_micros\", 0)\n",
    "            conversions = getattr(result.metrics, \"conversions\", 0)\n",
    "            conv_value = getattr(result.metrics, \"conversions_value\", 0)\n",
    "            campaign_id = getattr(campaign, \"id\", None)\n",
    "            campaign_name = getattr(campaign, \"name\", None)\n",
    "            rows.append({\n",
    "                \"customer_id\": int(cust_id) if cust_id is not None else cust_str,\n",
    "                \"date\": pd.to_datetime(str(seg_date)),\n",
    "                \"campaign_id\": int(campaign_id) if campaign_id is not None else None,\n",
    "                \"campaign_name\": campaign_name,\n",
    "                \"impressions\": int(impressions) if impressions is not None else 0,\n",
    "                \"clicks\": int(clicks) if clicks is not None else 0,\n",
    "                \"cost\": float(cost_micros) / 1_000_000.0 if cost_micros is not None else 0.0,\n",
    "                \"conversions\": float(conversions) if conversions is not None else 0.0,\n",
    "                \"conversion_value\": float(conv_value) if conv_value is not None else 0.0\n",
    "            })\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(rows)\n",
    "    # normalize date column\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.normalize()\n",
    "    return df\n",
    "\n",
    "# ---------- Simple monitor logic (same as previous simple version) ----------\n",
    "def safe_div(a, b):\n",
    "    return np.where(b == 0, 0.0, a / b)\n",
    "\n",
    "def compute_daily_metrics(df):\n",
    "    group = [\"date\", \"customer_id\", \"campaign_id\", \"campaign_name\"]\n",
    "    agg = df.groupby(group, as_index=False).agg({\n",
    "        \"impressions\": \"sum\",\n",
    "        \"clicks\": \"sum\",\n",
    "        \"cost\": \"sum\",\n",
    "        \"conversions\": \"sum\",\n",
    "        \"conversion_value\": \"sum\"\n",
    "    })\n",
    "    agg[\"ctr\"] = safe_div(agg[\"clicks\"], agg[\"impressions\"])\n",
    "    agg[\"cpc\"] = safe_div(agg[\"cost\"], agg[\"clicks\"])\n",
    "    agg[\"conversion_rate\"] = safe_div(agg[\"conversions\"], agg[\"clicks\"])\n",
    "    agg[\"cpa\"] = safe_div(agg[\"cost\"], agg[\"conversions\"])\n",
    "    agg[\"roi\"] = safe_div(agg[\"conversion_value\"], agg[\"cost\"])\n",
    "    return agg\n",
    "\n",
    "def historical_average(metrics_df, target_date, days):\n",
    "    hist_end = pd.to_datetime(target_date) - pd.Timedelta(days=1)\n",
    "    hist_start = hist_end - pd.Timedelta(days=days - 1)\n",
    "    hist = metrics_df[(metrics_df[\"date\"] >= hist_start) & (metrics_df[\"date\"] <= hist_end)]\n",
    "    if hist.empty:\n",
    "        return pd.DataFrame()\n",
    "    cols = [\"customer_id\", \"campaign_id\"]\n",
    "    hist_avg = hist.groupby(cols).agg({\n",
    "        \"impressions\": \"mean\", \"clicks\": \"mean\", \"cost\": \"mean\",\n",
    "        \"conversions\": \"mean\", \"conversion_value\": \"mean\",\n",
    "        \"ctr\": \"mean\", \"cpc\": \"mean\", \"conversion_rate\": \"mean\", \"cpa\": \"mean\", \"roi\": \"mean\"\n",
    "    }).reset_index()\n",
    "    hist_avg = hist_avg.rename(columns={c: f\"{c}_hist\" for c in hist_avg.columns if c not in cols})\n",
    "    return hist_avg\n",
    "\n",
    "def detect_breaches(target_df, hist_avg):\n",
    "    merged = target_df.merge(hist_avg, on=[\"customer_id\", \"campaign_id\"], how=\"left\")\n",
    "    merged[\"ctr_pct\"] = (merged[\"ctr\"] - merged.get(\"ctr_hist\", 0)) / (merged.get(\"ctr_hist\", 0) + EPS)\n",
    "    merged[\"cpc_pct\"] = (merged[\"cpc\"] - merged.get(\"cpc_hist\", 0)) / (merged.get(\"cpc_hist\", 0) + EPS)\n",
    "    merged[\"conv_rate_pct\"] = (merged[\"conversion_rate\"] - merged.get(\"conversion_rate_hist\", 0)) / (merged.get(\"conversion_rate_hist\", 0) + EPS)\n",
    "    merged[\"cpa_pct\"] = (merged[\"cpa\"] - merged.get(\"cpa_hist\", 0)) / (merged.get(\"cpa_hist\", 0) + EPS)\n",
    "\n",
    "    alerts = []\n",
    "    for _, r in merged.iterrows():\n",
    "        if r[\"impressions\"] < MIN_IMPRESSIONS or r[\"clicks\"] < MIN_CLICKS:\n",
    "            continue\n",
    "        breach_items = []\n",
    "        if \"ctr\" in THRESHOLDS and pd.notnull(r.get(\"ctr_hist\")) and r[\"ctr_pct\"] >= THRESHOLDS[\"ctr\"]:\n",
    "            breach_items.append((\"ctr\", r[\"ctr\"], r.get(\"ctr_hist\"), r[\"ctr_pct\"]))\n",
    "        if \"cpc\" in THRESHOLDS and pd.notnull(r.get(\"cpc_hist\")) and r[\"cpc_pct\"] >= THRESHOLDS[\"cpc\"]:\n",
    "            breach_items.append((\"cpc\", r[\"cpc\"], r.get(\"cpc_hist\"), r[\"cpc_pct\"]))\n",
    "        if \"conversion_rate\" in THRESHOLDS and pd.notnull(r.get(\"conversion_rate_hist\")):\n",
    "            th = THRESHOLDS[\"conversion_rate\"]\n",
    "            if th < 0 and r[\"conv_rate_pct\"] <= th:\n",
    "                breach_items.append((\"conversion_rate_drop\", r[\"conversion_rate\"], r.get(\"conversion_rate_hist\"), r[\"conv_rate_pct\"]))\n",
    "            elif th >= 0 and r[\"conv_rate_pct\"] >= th:\n",
    "                breach_items.append((\"conversion_rate_increase\", r[\"conversion_rate\"], r.get(\"conversion_rate_hist\"), r[\"conv_rate_pct\"]))\n",
    "        if \"cpa\" in THRESHOLDS and pd.notnull(r.get(\"cpa_hist\")) and r[\"cpa_pct\"] >= THRESHOLDS[\"cpa\"]:\n",
    "            breach_items.append((\"cpa\", r[\"cpa\"], r.get(\"cpa_hist\"), r[\"cpa_pct\"]))\n",
    "        if breach_items:\n",
    "            alerts.append({\n",
    "                \"customer_id\": r[\"customer_id\"],\n",
    "                \"campaign_id\": r[\"campaign_id\"],\n",
    "                \"campaign_name\": r[\"campaign_name\"],\n",
    "                \"date\": pd.to_datetime(r[\"date\"]).date().isoformat(),\n",
    "                \"impressions\": int(r[\"impressions\"]),\n",
    "                \"clicks\": int(r[\"clicks\"]),\n",
    "                \"cost\": float(r[\"cost\"]),\n",
    "                \"conversions\": float(r[\"conversions\"]),\n",
    "                \"conversion_value\": float(r[\"conversion_value\"]),\n",
    "                \"breach_details\": \"; \".join([f\"{m}: {cur:.4g} vs {hist:.4g} ({pct:+.1%})\" for m, cur, hist, pct in breach_items])\n",
    "            })\n",
    "    return pd.DataFrame(alerts), merged\n",
    "\n",
    "def export_and_email(daily_all, daily_target, alerts_df, latest_date):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    ds = latest_date.strftime(\"%Y%m%d\")\n",
    "    daily_all.to_csv(os.path.join(OUTPUT_DIR, f\"daily_all_{ds}.csv\"), index=False)\n",
    "    daily_target.to_csv(os.path.join(OUTPUT_DIR, f\"daily_target_{ds}.csv\"), index=False)\n",
    "    alerts_df.to_csv(os.path.join(OUTPUT_DIR, f\"alerts_{ds}.csv\"), index=False)\n",
    "    # excel workbook\n",
    "    try:\n",
    "        excel_path = os.path.join(OUTPUT_DIR, f\"campaign_report_{ds}.xlsx\")\n",
    "        with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "            daily_all.to_excel(writer, sheet_name=\"daily_all\", index=False)\n",
    "            daily_target.to_excel(writer, sheet_name=\"daily_target\", index=False)\n",
    "            alerts_df.to_excel(writer, sheet_name=\"alerts\", index=False)\n",
    "    except Exception as e:\n",
    "        print(\"Excel export error (openpyxl?), continuing:\", e)\n",
    "\n",
    "    # Email subject: one day before latest_date (as requested)\n",
    "    subject_date = (latest_date - timedelta(days=1)).date().isoformat()\n",
    "    subject = f\"Campaign report alerts - {subject_date}\"\n",
    "    if alerts_df.empty:\n",
    "        body = f\"<p>Hi Team,</p><p>No campaign breaches detected for {latest_date.date()}.</p><p>Reports saved to: {os.path.abspath(OUTPUT_DIR)}</p>\"\n",
    "    else:\n",
    "        body = f\"<p>Hi Team,</p><p>Campaign breaches detected for {latest_date.date()}. See table below and exported files.</p>\"\n",
    "        body += alerts_df.to_html(index=False, escape=False)\n",
    "        body += f\"<p>Exports saved to: {os.path.abspath(OUTPUT_DIR)}</p>\"\n",
    "\n",
    "    send_email(subject, body)\n",
    "    print(\"Exported files and attempted email send. Output folder:\", os.path.abspath(OUTPUT_DIR))\n",
    "\n",
    "# ---------- Runner ----------\n",
    "def run():\n",
    "    if not CUSTOMER_IDS or CUSTOMER_IDS[0].startswith(\"INSERT\"):\n",
    "        print(\"Please set CUSTOMER_IDS at top of the script to your Google Ads customer id(s). Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"Fetching data from Google Ads...\")\n",
    "    df = fetch_google_ads_data(CUSTOMER_IDS, LOOKBACK_DAYS)\n",
    "    if df.empty:\n",
    "        print(\"No data returned from Google Ads. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"Computing daily metrics...\")\n",
    "    daily = compute_daily_metrics(df)\n",
    "    latest_date = daily[\"date\"].max()\n",
    "    print(\"Latest date in data:\", latest_date.date())\n",
    "\n",
    "    target_day = daily[daily[\"date\"] == latest_date].copy()\n",
    "    if target_day.empty:\n",
    "        print(\"No rows for latest date; exiting.\")\n",
    "        return\n",
    "\n",
    "    hist_avg = historical_average(daily, latest_date, HIST_DAYS)\n",
    "    alerts_df, merged = detect_breaches(target_day, hist_avg)\n",
    "    export_and_email(daily, target_day, alerts_df, latest_date)\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
